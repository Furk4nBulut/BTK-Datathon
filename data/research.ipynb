{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/evaluation\n",
   "id": "b12e4c83e0ffbe28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n"
   ],
   "id": "623b57f22b55712e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "df = train._append(test,ignore_index=False).reset_index()\n",
    "\n",
    "df = df.drop(\"index\", axis=1)\n"
   ],
   "id": "5f4d83f78d5f1a6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def check_df(dataframe):\n",
    "    print(\"##################### Shape #####################\")\n",
    "    print(dataframe.shape)\n",
    "    print(\"##################### Types #####################\")\n",
    "    print(dataframe.dtypes)\n",
    "    print(\"##################### Head #####################\")\n",
    "    print(dataframe.head(3))\n",
    "    print(\"##################### Tail #####################\")\n",
    "    print(dataframe.tail(3))\n",
    "    print(\"##################### NA #####################\")\n",
    "    print(dataframe.isnull().sum())\n",
    "    print(\"##################### Quantiles #####################\")\n",
    "    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n"
   ],
   "id": "9841b58d965bb128",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    \"\"\"\n",
    "    grab_col_names for given dataframe\n",
    "\n",
    "    :param dataframe:\n",
    "    :param cat_th:\n",
    "    :param car_th:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
    "                   dataframe[col].dtypes != \"O\"]\n",
    "\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
    "                   dataframe[col].dtypes == \"O\"]\n",
    "\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "\n",
    "    print(f\"Observations: {dataframe.shape[0]}\")\n",
    "    print(f\"Variables: {dataframe.shape[1]}\")\n",
    "    print(f'cat_cols: {len(cat_cols)}')\n",
    "    print(f'num_cols: {len(num_cols)}')\n",
    "    print(f'cat_but_car: {len(cat_but_car)}')\n",
    "    print(f'num_but_cat: {len(num_but_cat)}')\n",
    "\n",
    "    # cat_cols + num_cols + cat_but_car = değişken sayısı.\n",
    "    # num_but_cat cat_cols'un içerisinde zaten.\n",
    "    # dolayısıyla tüm şu 3 liste ile tüm değişkenler seçilmiş olacaktır: cat_cols + num_cols + cat_but_car\n",
    "    # num_but_cat sadece raporlama için verilmiştir.\n",
    "\n",
    "    return cat_cols, cat_but_car, num_cols\n",
    "\n",
    "cat_cols, cat_but_car, num_cols = grab_col_names(df)\n"
   ],
   "id": "895c7c6fe5291917",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cat_summary(dataframe, col_name, plot=False):\n",
    "    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
    "                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
    "\n",
    "    if plot:\n",
    "        sns.countplot(x=dataframe[col_name], data=dataframe)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "for col in cat_cols:\n",
    "    cat_summary(df, col)\n",
    "\n"
   ],
   "id": "41ae5b3561dd164",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def num_summary(dataframe, numerical_col, plot=False):\n",
    "    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n",
    "    print(dataframe[numerical_col].describe(quantiles).T)\n",
    "\n",
    "    if plot:\n",
    "        dataframe[numerical_col].hist(bins=50)\n",
    "        plt.xlabel(numerical_col)\n",
    "        plt.title(numerical_col)\n",
    "        plt.show()\n",
    "\n",
    "    print(\"#####################################\")\n",
    "\n",
    "\n",
    "for col in num_cols:\n",
    "    num_summary(df, col, True)"
   ],
   "id": "ebe6a817358fb229",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def target_summary_with_cat(dataframe, target, categorical_col):\n",
    "    print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean()}), end=\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "for col in cat_cols:\n",
    "    target_summary_with_cat(df,\"SalePrice\",col)\n",
    "\n",
    "\n",
    "# Bağımlı değişkenin incelenmesi\n",
    "df[\"SalePrice\"].hist(bins=100)\n",
    "plt.show()\n",
    "\n",
    "# Bağımlı değişkenin logaritmasının incelenmesi\n",
    "np.log1p(df['SalePrice']).hist(bins=50)\n",
    "plt.show()\n"
   ],
   "id": "673d6896bb6fc6c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "corr = df[num_cols].corr()\n",
    "corr\n",
    "\n",
    "# Korelasyonların gösterilmesi\n",
    "sns.set(rc={'figure.figsize': (12, 12)})\n",
    "sns.heatmap(corr, cmap=\"RdBu\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def high_correlated_cols(dataframe, plot=False, corr_th=0.70):\n",
    "    corr = dataframe.corr()\n",
    "    cor_matrix = corr.abs()\n",
    "    upper_triangle_matrix = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(np.bool))\n",
    "    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]\n",
    "    if plot:\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "        sns.set(rc={'figure.figsize': (15, 15)})\n",
    "        sns.heatmap(corr, cmap=\"RdBu\")\n",
    "        plt.show()\n",
    "    return drop_list\n"
   ],
   "id": "81a5692712c81756",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "feature engineering",
   "id": "887558a2a7c3db0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def outlier_thresholds(dataframe, variable, low_quantile=0.10, up_quantile=0.90):\n",
    "    quantile_one = dataframe[variable].quantile(low_quantile)\n",
    "    quantile_three = dataframe[variable].quantile(up_quantile)\n",
    "    interquantile_range = quantile_three - quantile_one\n",
    "    up_limit = quantile_three + 1.5 * interquantile_range\n",
    "    low_limit = quantile_one - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n"
   ],
   "id": "7def7c5ff0316272",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aykırı değer kontrolü\n",
    "def check_outlier(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "for col in num_cols:\n",
    "    if col != \"SalePrice\":\n",
    "      print(col, check_outlier(df, col))"
   ],
   "id": "635fcb28e8794466",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aykırı değerlerin baskılanması\n",
    "def replace_with_thresholds(dataframe, variable):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n",
    "\n",
    "\n",
    "for col in num_cols:\n",
    "    if col != \"SalePrice\":\n",
    "        replace_with_thresholds(df,col)\n"
   ],
   "id": "2ee5718db819ca19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def missing_values_table(dataframe, na_name=False):\n",
    "    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n",
    "\n",
    "    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n",
    "\n",
    "    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n",
    "\n",
    "    print(missing_df, end=\"\\n\")\n",
    "\n",
    "    if na_name:\n",
    "        return na_columns\n",
    "\n",
    "missing_values_table(df)\n"
   ],
   "id": "d67b831177c30aea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"Alley\"].value_counts()\n",
    "df[\"BsmtQual\"].value_counts()\n",
    "\n",
    "\n",
    "# Bazı değişkenlerdeki boş değerler evin o özelliğe sahip olmadığını ifade etmektedir\n",
    "no_cols = [\"Alley\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"FireplaceQu\",\n",
    "           \"GarageType\",\"GarageFinish\",\"GarageQual\",\"GarageCond\",\"PoolQC\",\"Fence\",\"MiscFeature\"]\n",
    "\n",
    "# Kolonlardaki boşlukların \"No\" ifadesi ile doldurulması\n",
    "for col in no_cols:\n",
    "    df[col].fillna(\"No\",inplace=True)\n",
    "\n",
    "missing_values_table(df)\n",
    "\n",
    "def quick_missing_imp(data, num_method=\"median\", cat_length=20, target=\"SalePrice\"):\n",
    "    variables_with_na = [col for col in data.columns if data[col].isnull().sum() > 0]  # Eksik değere sahip olan değişkenler listelenir\n",
    "\n",
    "    temp_target = data[target]\n",
    "\n",
    "    print(\"# BEFORE\")\n",
    "    print(data[variables_with_na].isnull().sum(), \"\\n\\n\")  # Uygulama öncesi değişkenlerin eksik değerlerinin sayısı\n",
    "\n",
    "    # değişken object ve sınıf sayısı cat_lengthe eşit veya altındaysa boş değerleri mode ile doldur\n",
    "    data = data.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= cat_length) else x, axis=0)\n",
    "\n",
    "    # num_method mean ise tipi object olmayan değişkenlerin boş değerleri ortalama ile dolduruluyor\n",
    "    if num_method == \"mean\":\n",
    "        data = data.apply(lambda x: x.fillna(x.mean()) if x.dtype != \"O\" else x, axis=0)\n",
    "    # num_method median ise tipi object olmayan değişkenlerin boş değerleri ortalama ile dolduruluyor\n",
    "    elif num_method == \"median\":\n",
    "        data = data.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)\n",
    "\n",
    "    data[target] = temp_target\n",
    "\n",
    "    print(\"# AFTER \\n Imputation method is 'MODE' for categorical variables!\")\n",
    "    print(\" Imputation method is '\" + num_method.upper() + \"' for numeric variables! \\n\")\n",
    "    print(data[variables_with_na].isnull().sum(), \"\\n\\n\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "df = quick_missing_imp(df, num_method=\"median\", cat_length=17)\n",
    "\n"
   ],
   "id": "f98fc7140ca01e1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rare_analyser(dataframe, target, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        print(col, \":\", len(dataframe[col].value_counts()))\n",
    "        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n",
    "                            \"RATIO\": dataframe[col].value_counts() / len(dataframe),\n",
    "                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n",
    "\n",
    "rare_analyser(df, \"SalePrice\", cat_cols)"
   ],
   "id": "b642ff39d7b9603e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rare_encoder(dataframe, rare_perc):\n",
    "    temp_df = dataframe.copy()\n",
    "\n",
    "    rare_columns = [col for col in temp_df.columns if temp_df[col].dtypes == 'O'\n",
    "                    and (temp_df[col].value_counts() / len(temp_df) < rare_perc).any(axis=None)]\n",
    "\n",
    "    for var in rare_columns:\n",
    "        tmp = temp_df[var].value_counts() / len(temp_df)\n",
    "        rare_labels = tmp[tmp < rare_perc].index\n",
    "        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])\n",
    "\n",
    "    return temp_df\n",
    "\n",
    "\n",
    "rare_encoder(df,0.01)"
   ],
   "id": "a6b143f58b78d21a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "df[\"NEW_1st*GrLiv\"] = df[\"1stFlrSF\"] * df[\"GrLivArea\"]\n",
    "\n",
    "df[\"NEW_Garage*GrLiv\"] = (df[\"GarageArea\"] * df[\"GrLivArea\"])\n",
    "\n",
    "df[\"TotalQual\"] = df[[\"OverallQual\", \"OverallCond\", \"ExterQual\", \"ExterCond\", \"BsmtCond\", \"BsmtFinType1\",\n",
    "                      \"BsmtFinType2\", \"HeatingQC\", \"KitchenQual\", \"Functional\", \"FireplaceQu\", \"GarageQual\", \"GarageCond\", \"Fence\"]].sum() # 42\n",
    "\n",
    "\n",
    "# Total Floor\n",
    "df[\"NEW_TotalFlrSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"] # 32\n",
    "\n",
    "# Total Finished Basement Area\n",
    "df[\"NEW_TotalBsmtFin\"] = df.BsmtFinSF1 + df.BsmtFinSF2 # 56\n",
    "\n",
    "# Porch Area\n",
    "df[\"NEW_PorchArea\"] = df.OpenPorchSF + df.EnclosedPorch + df.ScreenPorch + df[\"3SsnPorch\"] + df.WoodDeckSF # 93\n",
    "\n",
    "# Total House Area\n",
    "df[\"NEW_TotalHouseArea\"] = df.NEW_TotalFlrSF + df.TotalBsmtSF # 156\n",
    "\n",
    "df[\"NEW_TotalSqFeet\"] = df.GrLivArea + df.TotalBsmtSF # 35\n",
    "\n",
    "\n",
    "# Lot Ratio\n",
    "df[\"NEW_LotRatio\"] = df.GrLivArea / df.LotArea # 64\n",
    "\n",
    "df[\"NEW_RatioArea\"] = df.NEW_TotalHouseArea / df.LotArea # 57\n",
    "\n",
    "df[\"NEW_GarageLotRatio\"] = df.GarageArea / df.LotArea # 69\n",
    "\n",
    "# MasVnrArea\n",
    "df[\"NEW_MasVnrRatio\"] = df.MasVnrArea / df.NEW_TotalHouseArea # 36\n",
    "\n",
    "# Dif Area\n",
    "df[\"NEW_DifArea\"] = (df.LotArea - df[\"1stFlrSF\"] - df.GarageArea - df.NEW_PorchArea - df.WoodDeckSF) # 73\n",
    "\n",
    "\n",
    "df[\"NEW_OverallGrade\"] = df[\"OverallQual\"] * df[\"OverallCond\"] # 61\n",
    "\n",
    "\n",
    "df[\"NEW_Restoration\"] = df.YearRemodAdd - df.YearBuilt # 31\n",
    "\n",
    "df[\"NEW_HouseAge\"] = df.YrSold - df.YearBuilt # 73\n",
    "\n",
    "df[\"NEW_RestorationAge\"] = df.YrSold - df.YearRemodAdd # 40\n",
    "\n",
    "df[\"NEW_GarageAge\"] = df.GarageYrBlt - df.YearBuilt # 17\n",
    "\n",
    "df[\"NEW_GarageRestorationAge\"] = np.abs(df.GarageYrBlt - df.YearRemodAdd) # 30\n",
    "\n",
    "df[\"NEW_GarageSold\"] = df.YrSold - df.GarageYrBlt # 48\n",
    "\n",
    "\n",
    "\n",
    "drop_list = [\"Street\", \"Alley\", \"LandContour\", \"Utilities\", \"LandSlope\",\"Heating\", \"PoolQC\", \"MiscFeature\",\"Neighborhood\"]\n",
    "\n",
    "# drop_list'teki değişkenlerin düşürülmesi\n",
    "df.drop(drop_list, axis=1, inplace=True)"
   ],
   "id": "23cc3674e48cc50e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cat_cols, cat_but_car, num_cols = grab_col_names(df)",
   "id": "cf50ed85bbedb856",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def label_encoder(dataframe, binary_col):\n",
    "    labelencoder = LabelEncoder()\n",
    "    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n",
    "    return dataframe\n",
    "\n",
    "binary_cols = [col for col in df.columns if df[col].dtypes == \"O\" and len(df[col].unique()) == 2]\n",
    "\n",
    "for col in binary_cols:\n",
    "    label_encoder(df, col)"
   ],
   "id": "834fe8be1176bf9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n",
    "    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n",
    "    return dataframe\n",
    "\n",
    "df = one_hot_encoder(df, cat_cols, drop_first=True)"
   ],
   "id": "c77b8715778a846d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "#  Train ve Test verisini ayırınız. (SalePrice değişkeni boş olan değerler test verisidir.)\n",
    "train_df = df[df['SalePrice'].notnull()]\n",
    "test_df = df[df['SalePrice'].isnull()]\n",
    "\n",
    "y = train_df['SalePrice'] # np.log1p(df['SalePrice'])\n",
    "X = train_df.drop([\"Id\", \"SalePrice\"], axis=1)\n",
    "\n",
    "# Train verisi ile model kurup, model başarısını değerlendiriniz.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=17)\n"
   ],
   "id": "c2b7cde9daec1810",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "models = [('LR', LinearRegression()),\n",
    "          #(\"Ridge\", Ridge()),\n",
    "          #(\"Lasso\", Lasso()),\n",
    "          #(\"ElasticNet\", ElasticNet()),\n",
    "          ('KNN', KNeighborsRegressor()),\n",
    "          ('CART', DecisionTreeRegressor()),\n",
    "          ('RF', RandomForestRegressor()),\n",
    "          #('SVR', SVR()),\n",
    "          ('GBM', GradientBoostingRegressor()),\n",
    "          (\"XGBoost\", XGBRegressor(objective='reg:squarederror')),\n",
    "          (\"LightGBM\", LGBMRegressor())]\n",
    "          # (\"CatBoost\", CatBoostRegressor(verbose=False))]\n"
   ],
   "id": "8eba51565dbe00a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for name, regressor in models:\n",
    "    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n",
    "    print(f\"RMSE: {round(rmse, 4)} ({name}) \")"
   ],
   "id": "fe44af4573061e0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['SalePrice'].mean()\n",
    "df['SalePrice'].std()"
   ],
   "id": "66a216d219cab76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "train_df = df[df['SalePrice'].notnull()]\n",
    "test_df = df[df['SalePrice'].isnull()]\n",
    "\n",
    "y = np.log1p(train_df['SalePrice'])\n",
    "X = train_df.drop([\"Id\", \"SalePrice\"], axis=1)\n"
   ],
   "id": "c979859abab653e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verinin eğitim ve tet verisi olarak bölünmesi\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=17)\n"
   ],
   "id": "8604f2330feb8ea1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "lgbm = LGBMRegressor().fit(X_train, y_train)\n",
    "y_pred = lgbm.predict(X_test)\n",
    "\n",
    "y_pred\n",
    "# Yapılan LOG dönüşümünün tersinin (inverse'nin) alınması\n",
    "new_y = np.expm1(y_pred)\n",
    "new_y\n",
    "new_y_test = np.expm1(y_test)\n",
    "new_y_test\n",
    "\n",
    "np.sqrt(mean_squared_error(new_y_test, new_y))"
   ],
   "id": "f840f523158ed9a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "lgbm_model = LGBMRegressor(random_state=46)\n",
    "\n",
    "rmse = np.mean(np.sqrt(-cross_val_score(lgbm_model, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n",
    "\n",
    "\n",
    "lgbm_params = {\"learning_rate\": [0.01, 0.1],\n",
    "               \"n_estimators\": [500, 1500]\n",
    "               #\"colsample_bytree\": [0.5, 0.7, 1]\n",
    "             }\n",
    "\n",
    "lgbm_gs_best = GridSearchCV(lgbm_model,\n",
    "                            lgbm_params,\n",
    "                            cv=3,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=True).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "final_model = lgbm_model.set_params(**lgbm_gs_best.best_params_).fit(X, y)\n",
    "\n",
    "rmse = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n"
   ],
   "id": "6c92f701827753ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_importance(model, features, num=len(X), save=False):\n",
    "\n",
    "    feature_imp = pd.DataFrame({\"Value\": model.feature_importances_, \"Feature\": features.columns})\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.set(font_scale=1)\n",
    "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[0:num])\n",
    "    plt.title(\"Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if save:\n",
    "        plt.savefig(\"importances.png\")\n",
    "\n",
    "model = LGBMRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "plot_importance(model, X)\n"
   ],
   "id": "921c92dbd385865a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "model = LGBMRegressor()\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(test_df.drop([\"Id\",\"SalePrice\"], axis=1))\n",
    "predictions = predictions*100000\n",
    "test_df[\"Id\"] = test_df[\"Id\"].astype(\"int32\")\n",
    "dictionary = {\"Id\": test_df[\"Id\"], \"SalePrice\": predictions}\n",
    "dfSubmission = pd.DataFrame(dictionary)\n",
    "dfSubmission.to_csv(\"housePricePredictions.csv\", index=False)\n"
   ],
   "id": "c33bde37dcbeffaa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
